{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 1.13.0 and Flower 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training/evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flower clients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Strategy customization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Server-side parameter **initialization**\n",
    "\n",
    "Flower, by default, initializes the global model by asking one random client for the initial parameters. In many cases, we want more control over parameter initialization though.\n",
    "Flower therefore allows you to directly pass the initial parameters to the Strategy.\n",
    "\n",
    "Passing initial_parameters to the FedAvg strategy prevents Flower from asking one of the clients for the initial parameters. If we look closely, we can see that the logs do not show any calls to the FlowerClient.get_parameters method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 16:05:43,903 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 16:05:45,318\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 16:05:46,743 | app.py:174 | Flower VCE: Ray initialized with resources: {'node:127.0.0.1': 1.0, 'memory': 12397450855.0, 'CPU': 8.0, 'object_store_memory': 2147483648.0}\n",
      "INFO flower 2022-12-07 16:05:46,745 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 16:05:46,745 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-12-07 16:05:46,746 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 16:05:46,747 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 16:05:46,748 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m [Client 6] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m [Client 5] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:05:54,022 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:05:54,030 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:05:54,031 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m Epoch 1: train loss 0.06420566886663437, accuracy 0.2328888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m Epoch 1: train loss 0.0642307847738266, accuracy 0.23866666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m Epoch 1: train loss 0.06421255320310593, accuracy 0.2311111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:05:57,263 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:05:57,264 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:05:57,264 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9801)\u001B[0m [Client 3] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9800)\u001B[0m [Client 5] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9798)\u001B[0m [Client 7] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m [Client 7] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m [Client 6] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m [Client 3] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:06:02,110 | server.py:229 | fit_round 2 received 3 results and 0 failures\n",
      "DEBUG flower 2022-12-07 16:06:02,118 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m Epoch 1: train loss 0.0560351237654686, accuracy 0.33666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m Epoch 1: train loss 0.05528373643755913, accuracy 0.34555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m Epoch 1: train loss 0.056825317442417145, accuracy 0.33644444444444443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:06:05,370 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flower 2022-12-07 16:06:05,371 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9801)\u001B[0m [Client 2] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9798)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9800)\u001B[0m [Client 6] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m [Client 5] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m [Client 8] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:06:11,300 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "DEBUG flower 2022-12-07 16:06:11,308 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9801)\u001B[0m Epoch 1: train loss 0.052973777055740356, accuracy 0.38355555555555554\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9798)\u001B[0m Epoch 1: train loss 0.052766550332307816, accuracy 0.38177777777777777\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9800)\u001B[0m Epoch 1: train loss 0.05191192403435707, accuracy 0.39644444444444443\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9798)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9801)\u001B[0m [Client 5] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9800)\u001B[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:06:14,930 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:06:14,931 | server.py:144 | FL finished in 28.182679120000103\n",
      "INFO flower 2022-12-07 16:06:14,932 | app.py:192 | app_fit: losses_distributed [(1, 0.05941859984397888), (2, 0.05397985498110453), (3, 0.050876362244288126)]\n",
      "INFO flower 2022-12-07 16:06:14,933 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 16:06:14,934 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-07 16:06:14,935 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.05941859984397888\n\tround 2: 0.05397985498110453\n\tround 3: 0.050876362244288126"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "params = get_parameters(Net())\n",
    "\n",
    "# Pass parameters to the Strategy for server-side parameter initialization\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Starting with a customized strategy\n",
    "You can choose FedAvg or FedAdagrad or others strategies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create FedAdam strategy\n",
    "strategy=fl.server.strategy.FedAdagrad(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Server-side parameter **evaluation**\n",
    "\n",
    "**Centralized Evaluation (or server-side evaluation)**\n",
    "is conceptually simple: it works the same way that evaluation in centralized machine learning does.\n",
    "If there is a **server-side dataset that can be used for evaluation purposes**, then that’s great.\n",
    "We can evaluate the newly aggregated model after each round of training without having to send the model to clients.\n",
    "We’re also fortunate in the sense that our entire evaluation dataset is available at all times.\n",
    "\n",
    "**Federated Evaluation (or client-side evaluation)**\n",
    " is more complex, but also more powerful: it doesn’t require a centralized dataset and allows us to evaluate models over a larger set of data, which often yields more realistic evaluation results.\n",
    " In fact, many scenarios require us to use Federated Evaluation if we want to get representative evaluation results at all.\n",
    " But this power comes at a cost: once we start to evaluate on the client side, **we should be aware that our evaluation dataset can change over consecutive rounds of learning if those clients are not always available**.\n",
    " Moreover, **the dataset held by each client can also change over consecutive rounds**.\n",
    " This can lead to evaluation results that are not stable, so even if we would not change the model, we’d see our evaluation results fluctuate over consecutive rounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# The `evaluate` function will be by Flower called after every round\n",
    "def evaluate(\n",
    "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net()\n",
    "    valloader = valloaders[0]\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, valloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 16:31:15,926 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 16:31:19,203\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 16:31:20,582 | app.py:174 | Flower VCE: Ray initialized with resources: {'object_store_memory': 2147483648.0, 'CPU': 8.0, 'node:127.0.0.1': 1.0, 'memory': 14397673063.0}\n",
      "INFO flower 2022-12-07 16:31:20,583 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 16:31:20,584 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-12-07 16:31:20,585 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 16:31:20,752 | server.py:91 | initial parameters (loss, other metrics): 0.07370910120010377, {'accuracy': 0.098}\n",
      "INFO flower 2022-12-07 16:31:20,753 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 16:31:20,754 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.07370910120010377 / accuracy 0.098\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m [Client 8] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m [Client 6] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:27,854 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:31:27,861 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "INFO flower 2022-12-07 16:31:28,007 | server.py:116 | fit progress: (1, 0.06255912685394287, {'accuracy': 0.318}, 7.253054238999994)\n",
      "DEBUG flower 2022-12-07 16:31:28,007 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m Epoch 1: train loss 0.0646289512515068, accuracy 0.23244444444444445\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m Epoch 1: train loss 0.06527634710073471, accuracy 0.22933333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m Epoch 1: train loss 0.06476641446352005, accuracy 0.2388888888888889\n",
      "Server-side evaluation loss 0.06255912685394287 / accuracy 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:31,141 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:31:31,142 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:31:31,142 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9924)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9922)\u001B[0m [Client 7] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9926)\u001B[0m [Client 3] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m [Client 8] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m [Client 5] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:36,965 | server.py:229 | fit_round 2 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:31:37,100 | server.py:116 | fit progress: (2, 0.05607489824295044, {'accuracy': 0.372}, 16.34668154000019)\n",
      "DEBUG flower 2022-12-07 16:31:37,101 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m Epoch 1: train loss 0.05891004949808121, accuracy 0.31022222222222223\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m Epoch 1: train loss 0.05818561464548111, accuracy 0.3233333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m Epoch 1: train loss 0.058941107243299484, accuracy 0.30733333333333335\n",
      "Server-side evaluation loss 0.05607489824295044 / accuracy 0.372\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9924)\u001B[0m [Client 5] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9922)\u001B[0m [Client 8] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9926)\u001B[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:40,773 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flower 2022-12-07 16:31:40,774 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m [Client 2] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m [Client 3] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m [Client 6] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:46,271 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:31:46,423 | server.py:116 | fit progress: (3, 0.05349695038795471, {'accuracy': 0.402}, 25.669028311000147)\n",
      "DEBUG flower 2022-12-07 16:31:46,424 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9922)\u001B[0m Epoch 1: train loss 0.054621271789073944, accuracy 0.3571111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9926)\u001B[0m Epoch 1: train loss 0.05538584291934967, accuracy 0.35\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9924)\u001B[0m Epoch 1: train loss 0.05476818233728409, accuracy 0.35844444444444445\n",
      "Server-side evaluation loss 0.05349695038795471 / accuracy 0.402\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9924)\u001B[0m [Client 3] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9926)\u001B[0m [Client 9] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9922)\u001B[0m [Client 8] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:31:49,774 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:31:49,775 | server.py:144 | FL finished in 29.021321522000108\n",
      "INFO flower 2022-12-07 16:31:49,776 | app.py:192 | app_fit: losses_distributed [(1, 0.06284476073582967), (2, 0.0545183969338735), (3, 0.052845369974772134)]\n",
      "INFO flower 2022-12-07 16:31:49,777 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 16:31:49,778 | app.py:194 | app_fit: losses_centralized [(0, 0.07370910120010377), (1, 0.06255912685394287), (2, 0.05607489824295044), (3, 0.05349695038795471)]\n",
      "INFO flower 2022-12-07 16:31:49,779 | app.py:195 | app_fit: metrics_centralized {'accuracy': [(0, 0.098), (1, 0.318), (2, 0.372), (3, 0.402)]}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.06284476073582967\n\tround 2: 0.0545183969338735\n\tround 3: 0.052845369974772134\nHistory (loss, centralized):\n\tround 0: 0.07370910120010377\n\tround 1: 0.06255912685394287\n\tround 2: 0.05607489824295044\n\tround 3: 0.05349695038795471\nHistory (metrics, centralized):\n{'accuracy': [(0, 0.098), (1, 0.318), (2, 0.372), (3, 0.402)]}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "    evaluate_fn=evaluate,  # Pass the evaluation function\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sending/receiving arbitrary values to/from clients\n",
    "In some situations, we want to configure client-side execution (trainig, evaluation) from the server-side.  (i.e. the number of local epochs)\n",
    " Flower provides a way to send configuration values from the server to the clients using a dictionary.\n",
    " Let’s look at an example where the clients receive values from the server through the config parameter in fit (config is also available in evaluate).\n",
    " The fit method receives the configuration dictionary through the config parameter and can then read values from this dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Read values from config\n",
    "        server_round = config[\"server_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round,  # The current round of federated learning\n",
    "        \"local_epochs\": 1 if server_round < 2 else 2,  #\n",
    "    }\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the client logs now include the current round of federated learning (which they read from the config dictionary).\n",
    "We can also configure local training to run for one epoch during the first and second round of federated learning, and then for two epochs during the third round.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 16:47:13,131 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 16:47:17,633\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 16:47:18,889 | app.py:174 | Flower VCE: Ray initialized with resources: {'object_store_memory': 2147483648.0, 'memory': 15349331968.0, 'CPU': 8.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flower 2022-12-07 16:47:18,891 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 16:47:18,892 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-12-07 16:47:18,892 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 16:47:19,075 | server.py:91 | initial parameters (loss, other metrics): 0.07371789598464966, {'accuracy': 0.098}\n",
      "INFO flower 2022-12-07 16:47:19,076 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 16:47:19,077 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.07371789598464966 / accuracy 0.098\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m [Client 2, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m [Client 8, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m [Client 6, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:26,174 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:47:26,181 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "INFO flower 2022-12-07 16:47:26,323 | server.py:116 | fit progress: (1, 0.06295389723777771, {'accuracy': 0.256}, 7.246437159999914)\n",
      "DEBUG flower 2022-12-07 16:47:26,324 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m Epoch 1: train loss 0.06530040502548218, accuracy 0.2248888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m Epoch 1: train loss 0.06531316787004471, accuracy 0.23222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m Epoch 1: train loss 0.06542231887578964, accuracy 0.23066666666666666\n",
      "Server-side evaluation loss 0.06295389723777771 / accuracy 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:29,531 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:47:29,532 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:47:29,533 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9999)\u001B[0m [Client 2] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9997)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10000)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m [Client 8, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m [Client 6, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m [Client 7, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m Epoch 1: train loss 0.057264018803834915, accuracy 0.3322222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m Epoch 1: train loss 0.05819209665060043, accuracy 0.31\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m Epoch 1: train loss 0.056809861212968826, accuracy 0.3353333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:37,448 | server.py:229 | fit_round 2 received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m Epoch 2: train loss 0.05154111236333847, accuracy 0.39466666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m Epoch 2: train loss 0.05313851311802864, accuracy 0.37755555555555553\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m Epoch 2: train loss 0.051574934273958206, accuracy 0.4051111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 16:47:37,653 | server.py:116 | fit progress: (2, 0.052439891815185546, {'accuracy': 0.404}, 18.57650970800023)\n",
      "DEBUG flower 2022-12-07 16:47:37,654 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.052439891815185546 / accuracy 0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:41,168 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flower 2022-12-07 16:47:41,169 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9999)\u001B[0m [Client 3] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9997)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10000)\u001B[0m [Client 6] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m [Client 0, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m [Client 5, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m [Client 2, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m Epoch 1: train loss 0.05101577937602997, accuracy 0.4071111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m Epoch 1: train loss 0.05173691734671593, accuracy 0.39155555555555555\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m Epoch 1: train loss 0.05155443772673607, accuracy 0.3997777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:48,466 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:47:48,627 | server.py:116 | fit progress: (3, 0.04944743013381958, {'accuracy': 0.43}, 29.550311821999912)\n",
      "DEBUG flower 2022-12-07 16:47:48,628 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=9999)\u001B[0m Epoch 2: train loss 0.0485663115978241, accuracy 0.44133333333333336\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=9997)\u001B[0m Epoch 2: train loss 0.04866097494959831, accuracy 0.436\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10000)\u001B[0m Epoch 2: train loss 0.048769816756248474, accuracy 0.4211111111111111\n",
      "Server-side evaluation loss 0.04944743013381958 / accuracy 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:47:52,104 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flower 2022-12-07 16:47:52,105 | server.py:144 | FL finished in 33.0282801860003\n",
      "INFO flower 2022-12-07 16:47:52,106 | app.py:192 | app_fit: losses_distributed [(1, 0.06301429986953735), (2, 0.05221937688191732), (3, 0.04907084226608276)]\n",
      "INFO flower 2022-12-07 16:47:52,107 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 16:47:52,108 | app.py:194 | app_fit: losses_centralized [(0, 0.07371789598464966), (1, 0.06295389723777771), (2, 0.052439891815185546), (3, 0.04944743013381958)]\n",
      "INFO flower 2022-12-07 16:47:52,109 | app.py:195 | app_fit: metrics_centralized {'accuracy': [(0, 0.098), (1, 0.256), (2, 0.404), (3, 0.43)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9999)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=9997)\u001B[0m [Client 4] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10000)\u001B[0m [Client 9] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.06301429986953735\n\tround 2: 0.05221937688191732\n\tround 3: 0.04907084226608276\nHistory (loss, centralized):\n\tround 0: 0.07371789598464966\n\tround 1: 0.06295389723777771\n\tround 2: 0.052439891815185546\n\tround 3: 0.04944743013381958\nHistory (metrics, centralized):\n{'accuracy': [(0, 0.098), (1, 0.256), (2, 0.404), (3, 0.43)]}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "    evaluate_fn=evaluate,\n",
    "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,    # keeps the config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling federated learning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 1000\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 16:58:14,371 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 16:58:17,540\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 16:58:18,989 | app.py:174 | Flower VCE: Ray initialized with resources: {'node:127.0.0.1': 1.0, 'CPU': 8.0, 'memory': 15512628429.0, 'object_store_memory': 2147483648.0}\n",
      "INFO flower 2022-12-07 16:58:18,993 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 16:58:18,993 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-12-07 16:58:18,994 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 16:58:18,995 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 16:58:18,995 | server.py:215 | fit_round 1: strategy sampled 25 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 337, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 496, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 645, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 913, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 82, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 793, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 535, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 884, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10315325111150742, accuracy 0.022222222222222223\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10189681500196457, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10263987630605698, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10158716887235641, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.10261903703212738, accuracy 0.044444444444444446\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.10188218951225281, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10225855559110641, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.10153710842132568, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.103650763630867, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10211510211229324, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10175388306379318, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.10116454213857651, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10312497615814209, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.10257697850465775, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.1024894043803215, accuracy 0.0\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10149062424898148, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.10056012123823166, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.10119982808828354, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.10106465965509415, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.10026243329048157, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.10179059952497482, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.10012463480234146, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.10201632231473923, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.10128557682037354, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 901, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.1010717824101448, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 626, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 688, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10160844773054123, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.09969838708639145, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09672978520393372, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10199712216854095, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.10103142261505127, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.09956804662942886, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10100926458835602, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.0997929573059082, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 77, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10251867771148682, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10155356675386429, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.10131624341011047, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 101, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10100691020488739, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10036583244800568, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.10012541711330414, accuracy 0.4\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 887, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.1033167764544487, accuracy 0.044444444444444446\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10256146639585495, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.10048554837703705, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 699, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10237784683704376, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.10138687491416931, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 375, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 902, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10181715339422226, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10077241063117981, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09941404312849045, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.09971298277378082, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10237643122673035, accuracy 0.044444444444444446\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10225442051887512, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09993962198495865, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 992, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 2213 MiB, 34 objects, write throughput 409 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10222136974334717, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10092472285032272, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 689, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 145, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.10053155571222305, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.1025557592511177, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.1017594262957573, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10220275819301605, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10089632868766785, accuracy 0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:58:51,062 | server.py:229 | fit_round 1 received 25 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 985, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.1032525822520256, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.10027943551540375, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09963230788707733, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 363, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10220146179199219, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 694, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10153350979089737, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 444, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10204792022705078, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 518, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10224051773548126, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.10179250687360764, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.10087047517299652, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.10073743760585785, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.0998324304819107, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10056041926145554, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.10002613067626953, accuracy 0.15555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING flower 2022-12-07 16:58:51,146 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:58:51,147 | server.py:165 | evaluate_round 1: strategy sampled 50 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10090780258178711, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09996060281991959, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10064913332462311, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.10051509737968445, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 814] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 596] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 326] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 427] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 683] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 704] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 756] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 978] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 4131 MiB, 59 objects, write throughput 311 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 103] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 146] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 213] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 675] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 848] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 308] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 481] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 114] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 922] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 510] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 645] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 974] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 890] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 516] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 732] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 382] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 709] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 730] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 905] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 270] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 900] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 429] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 793] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 136] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 443] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 265] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 609] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 144] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 45] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 552] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 990] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 298] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 524] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 344] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 772] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 625] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 898] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 480] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 44] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 16:59:57,978 | server.py:179 | evaluate_round 1 received 50 results and 0 failures\n",
      "WARNING flower 2022-12-07 16:59:57,979 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 16:59:57,979 | server.py:215 | fit_round 2: strategy sampled 25 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 210] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 166] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 344, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10340940952301025, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 488, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10138554126024246, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.09992393851280212, accuracy 0.26666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 8404 MiB, 97 objects, write throughput 168 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 126, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.10260424017906189, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.09939602017402649, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 305, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.10156192630529404, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 385, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.10148218274116516, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 621, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10167325288057327, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 949, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10198015719652176, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.10046856850385666, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.09936065971851349, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10236214846372604, accuracy 0.022222222222222223\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.1007615178823471, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 54, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10235974937677383, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.10073377937078476, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 979, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10159634798765182, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10223189741373062, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10091819614171982, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.1012972965836525, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.10028864443302155, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.10035466402769089, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10130219161510468, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09937983751296997, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 338, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10214928537607193, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09968897700309753, accuracy 0.4888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.1001991555094719, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.09987984597682953, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.1002645269036293, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.10006557404994965, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.09609799087047577, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 127, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10252729803323746, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.1006782129406929, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.10007231682538986, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 110, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10280074179172516, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10140901058912277, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 826, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 89, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10205456614494324, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.09940511733293533, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09860304743051529, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 185, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10311713814735413, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10114908963441849, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.0999205932021141, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09999340772628784, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10109427571296692, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.0987299382686615, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.0966746136546135, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 370, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10275150090456009, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10160542279481888, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.10062719136476517, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 944, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10231660306453705, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.10098741203546524, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.10035035759210587, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 673, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10131371766328812, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10031488537788391, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.09926804155111313, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 413, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10238803923130035, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.10109905898571014, accuracy 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:00:25,817 | server.py:229 | fit_round 2 received 25 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:00:25,881 | server.py:165 | evaluate_round 2: strategy sampled 50 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 271, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10229034721851349, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.10100625455379486, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 44, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 173, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10146617144346237, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10006603598594666, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 900, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10200338065624237, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 425, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.1007925346493721, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09993703663349152, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.1017974466085434, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.10067537426948547, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.10070565342903137, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09872466325759888, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 551, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10198071599006653, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.10116934031248093, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.1010168269276619, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.09911803901195526, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09765705466270447, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.10028593242168427, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.09539786726236343, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.10027205944061279, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 505] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 44] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 329] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 772] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 236] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 849] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 829] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 956] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 180] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 925] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 149] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 142] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 59] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 298] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 837] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 581] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 58] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 759] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 89] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 674] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 65] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 697] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 938] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 933] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 808] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 39] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 437] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 62] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 738] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 254] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 472] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 51] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 291] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 600] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 750] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 908] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 387] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 743] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 783] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 979] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 500] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 245] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 109] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 995] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 153] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 967] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:01:14,446 | server.py:179 | evaluate_round 2 received 50 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:01:14,447 | server.py:215 | fit_round 3: strategy sampled 25 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 369] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 75] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 242] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 15] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 831, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10240012407302856, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m [Client 597, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 1: train loss 0.10098683834075928, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 727, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 962, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.1013665720820427, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.1006694883108139, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 2: train loss 0.09797561168670654, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 870, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10206563025712967, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 218, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.10177139937877655, accuracy 0.08888888888888889\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 8, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10058435052633286, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10057289153337479, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10187799483537674, accuracy 0.044444444444444446\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.09964726865291595, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10058)\u001B[0m Epoch 3: train loss 0.09645890444517136, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.09677764028310776, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 551, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10283176600933075, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.1008545458316803, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.09951744973659515, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.09750734269618988, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.09818405658006668, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.09822411090135574, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.09642430394887924, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.09120161086320877, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09432356804609299, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.0981082171201706, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 119, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10053450614213943, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.09852731227874756, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09605810046195984, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09957074373960495, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 795, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10124906152486801, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.0999571681022644, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09852518141269684, accuracy 0.17777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 16957 MiB, 195 objects, write throughput 177 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m [Client 382, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 396, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10289978235960007, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 1: train loss 0.10014453530311584, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 2: train loss 0.09618798643350601, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m [Client 556, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 1: train loss 0.10015475749969482, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.09914518892765045, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09798461198806763, accuracy 0.3333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10063)\u001B[0m Epoch 3: train loss 0.09350791573524475, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 90, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 852, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.10164148360490799, accuracy 0.06666666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 2: train loss 0.09756382554769516, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10061)\u001B[0m Epoch 3: train loss 0.09191607683897018, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10048208385705948, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.09907413274049759, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.09654343873262405, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.09995001554489136, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.0945470929145813, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 818, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10263805091381073, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.1006021797657013, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 979, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10048560053110123, accuracy 0.3111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.09754077345132828, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 719, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10313671827316284, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10017342120409012, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09961268305778503, accuracy 0.15555555555555556\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.09774678200483322, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09577886760234833, accuracy 0.2\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 333, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10215591639280319, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10000395029783249, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.0985201746225357, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 643, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10208246111869812, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.10017992556095123, accuracy 0.13333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09834761917591095, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m [Client 250, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 1: train loss 0.10043098777532578, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 2: train loss 0.10059118270874023, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10057)\u001B[0m Epoch 3: train loss 0.09648925065994263, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m [Client 206, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 1: train loss 0.10102083534002304, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 2: train loss 0.09817459434270859, accuracy 0.2222222222222222\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10062)\u001B[0m Epoch 3: train loss 0.09449039399623871, accuracy 0.24444444444444444\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m [Client 586, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 1: train loss 0.10186214745044708, accuracy 0.1111111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 2: train loss 0.09898584336042404, accuracy 0.17777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:01:39,963 | server.py:229 | fit_round 3 received 25 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:01:40,016 | server.py:165 | evaluate_round 3: strategy sampled 50 clients (out of 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m [Client 284, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 1: train loss 0.10157642513513565, accuracy 0.17777777777777778\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m [Client 173, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 1: train loss 0.1009516790509224, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10059)\u001B[0m Epoch 3: train loss 0.09708540141582489, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 2: train loss 0.09824725240468979, accuracy 0.3333333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10064)\u001B[0m Epoch 3: train loss 0.0963376984000206, accuracy 0.26666666666666666\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 2: train loss 0.09925661981105804, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10060)\u001B[0m Epoch 3: train loss 0.09538258612155914, accuracy 0.28888888888888886\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 910] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 472] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 880] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 867] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 129] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 776] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 179] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 260] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 189] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 523] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 710] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 503] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 313] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 11] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m \n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 327] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 481] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 304] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 863] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 293] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 350] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 499] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 93] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 346] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 439] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 370] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 425] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10062)\u001B[0m [Client 681] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 498] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 680] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 181] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 209] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 294] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 618] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 261] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 525] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 63] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 433] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 30] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 551] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 399] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 312] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10057)\u001B[0m [Client 248] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10058)\u001B[0m [Client 920] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:02:31,921 | server.py:179 | evaluate_round 3 received 50 results and 0 failures\n",
      "INFO flower 2022-12-07 17:02:31,922 | server.py:144 | FL finished in 252.926321379\n",
      "INFO flower 2022-12-07 17:02:31,923 | app.py:192 | app_fit: losses_distributed [(1, 0.46027768898010274), (2, 0.4553672752380373), (3, 0.45258576393127425)]\n",
      "INFO flower 2022-12-07 17:02:31,924 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 17:02:31,925 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-07 17:02:31,925 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10061)\u001B[0m [Client 183] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10063)\u001B[0m [Client 392] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10064)\u001B[0m [Client 925] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10060)\u001B[0m [Client 135] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10059)\u001B[0m [Client 506] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.46027768898010274\n\tround 2: 0.4553672752380373\n\tround 3: 0.45258576393127425"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 3,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.025,  # Train on 25 clients (each round)\n",
    "    fraction_evaluate=0.05,  # Evaluate on 50 clients (each round)\n",
    "    min_fit_clients=20,\n",
    "    min_evaluate_clients=40,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "    on_fit_config_fn=fit_config,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STRATEGY\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a Strategy from scratch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return []\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None, {}\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return []\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None, {}\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 17:14:35,130 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 17:14:39,934\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 17:14:41,331 | app.py:174 | Flower VCE: Ray initialized with resources: {'memory': 17911634330.0, 'object_store_memory': 2147483648.0, 'node:127.0.0.1': 1.0, 'CPU': 8.0}\n",
      "INFO flower 2022-12-07 17:14:41,333 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 17:14:41,336 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-12-07 17:14:41,337 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 17:14:41,338 | server.py:101 | FL starting\n",
      "INFO flower 2022-12-07 17:14:41,339 | server.py:213 | fit_round 1: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,340 | server.py:163 | evaluate_round 1: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,341 | server.py:213 | fit_round 2: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,342 | server.py:163 | evaluate_round 2: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,343 | server.py:213 | fit_round 3: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,344 | server.py:163 | evaluate_round 3: no clients selected, cancel\n",
      "INFO flower 2022-12-07 17:14:41,345 | server.py:144 | FL finished in 0.006728989999828627\n",
      "INFO flower 2022-12-07 17:14:41,346 | app.py:192 | app_fit: losses_distributed []\n",
      "INFO flower 2022-12-07 17:14:41,348 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 17:14:41,349 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-07 17:14:41,349 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=FedCustom(),  # <-- pass the new strategy here\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Client and NumPyClient\n",
    "In previous parts of this tutorial, we’ve based our client on NumPyClient, a convenience class which makes it easy to work with machine learning libraries that have good NumPy interoperability.\n",
    "With Client, we gain a lot of flexibility that we didn’t have before, but we’ll also have to do a few things the we didn’t have to do before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Revisiting NumPyClient\n",
    "We’ve seen this before, there’s nothing new so far. The only tiny difference compared to the previous notebook is naming, we’ve changed FlowerClient to FlowerNumPyClient and client_fn to numpyclient_fn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class FlowerNumPyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def numpyclient_fn(cid) -> FlowerNumPyClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerNumPyClient(cid, net, trainloader, valloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 17:19:41,493 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 17:19:45,418\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 17:19:46,737 | app.py:174 | Flower VCE: Ray initialized with resources: {'object_store_memory': 2147483648.0, 'node:127.0.0.1': 1.0, 'CPU': 8.0, 'memory': 17722780058.0}\n",
      "INFO flower 2022-12-07 17:19:46,738 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 17:19:46,739 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flower 2022-12-07 17:19:49,462 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flower 2022-12-07 17:19:49,463 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 17:19:49,463 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 17:19:49,464 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_get_parameters pid=10133)\u001B[0m [Client 0] get_parameters\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m [Client 1] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m Epoch 1: train loss 0.06601455807685852, accuracy 0.20644444444444446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:19:54,675 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-07 17:19:54,681 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 17:19:54,682 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m Epoch 1: train loss 0.06409581750631332, accuracy 0.23555555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:19:57,290 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-07 17:19:57,290 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 17:19:57,291 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10133)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10134)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:20:01,587 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:20:01,592 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m Epoch 1: train loss 0.05578812584280968, accuracy 0.3406666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m Epoch 1: train loss 0.05612076446413994, accuracy 0.3413333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:20:03,851 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:20:03,852 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10134)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10133)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m [Client 1] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:20:07,664 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:20:07,670 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10133)\u001B[0m Epoch 1: train loss 0.05136294290423393, accuracy 0.40066666666666667\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10134)\u001B[0m Epoch 1: train loss 0.05197069048881531, accuracy 0.3948888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:20:10,055 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
      "INFO flower 2022-12-07 17:20:10,055 | server.py:144 | FL finished in 20.591251875000125\n",
      "INFO flower 2022-12-07 17:20:10,056 | app.py:192 | app_fit: losses_distributed [(1, 0.06073317456245422), (2, 0.055544139623641964), (3, 0.05297538387775422)]\n",
      "INFO flower 2022-12-07 17:20:10,057 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 17:20:10,057 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-07 17:20:10,057 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10134)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10133)\u001B[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.06073317456245422\n\tround 2: 0.055544139623641964\n\tround 3: 0.05297538387775422"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=numpyclient_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let’s dive a little bit deeper and discuss how Flower executes this simulation. Whenever a client is selected to do some work, start_simulation calls the function numpyclient_fn to create an instance of our FlowerNumPyClient (along with loading the model and the data).\n",
    "\n",
    "But here’s the perhaps surprising part: Flower doesn’t actually use the FlowerNumPyClient object directly. Instead, it wraps the object to makes it look like a subclass of flwr.client.Client, not flwr.client.NumPyClient.\n",
    " In fact, the Flower core framework **doesn’t know how to handle NumPyClient’s, it only knows how to handle Client’s**. NumPyClient is just a convenience abstraction built on top of Client."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Moving from NumPyClient to Client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from flwr.common import Code, EvaluateIns, EvaluateRes, FitIns, FitRes, GetParametersIns, GetParametersRes, Status\n",
    "from flwr.common import ndarrays_to_parameters, parameters_to_ndarrays\n",
    "\n",
    "\n",
    "class FlowerClient(fl.client.Client):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "\n",
    "        # Get parameters as a list of NumPy ndarray's\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters,\n",
    "        )\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        # Update local model, train, get updated parameters\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader),\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        # return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(loss),\n",
    "            num_examples=len(self.valloader),\n",
    "            metrics={\"accuracy\": float(accuracy)},\n",
    "        )\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-07 17:22:46,721 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-07 17:22:50,529\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-07 17:22:52,070 | app.py:174 | Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:127.0.0.1': 1.0, 'memory': 17762622669.0, 'object_store_memory': 2147483648.0}\n",
      "INFO flower 2022-12-07 17:22:52,071 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-07 17:22:52,072 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flower 2022-12-07 17:22:54,322 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flower 2022-12-07 17:22:54,323 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-07 17:22:54,323 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-07 17:22:54,324 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_get_parameters pid=10155)\u001B[0m [Client 1] get_parameters\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m [Client 1] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m Epoch 1: train loss 0.06513454020023346, accuracy 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:22:59,964 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-07 17:22:59,970 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 17:22:59,970 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m Epoch 1: train loss 0.06510709971189499, accuracy 0.2157777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:23:02,229 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-07 17:23:02,230 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-07 17:23:02,230 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10155)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10156)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m [Client 1] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:23:06,076 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:23:06,082 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m Epoch 1: train loss 0.057452887296676636, accuracy 0.3253333333333333\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m Epoch 1: train loss 0.05869227275252342, accuracy 0.32755555555555554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:23:08,268 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:23:08,269 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10156)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10155)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:23:12,367 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-07 17:23:12,372 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=10155)\u001B[0m Epoch 1: train loss 0.05398540571331978, accuracy 0.37444444444444447\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=10156)\u001B[0m Epoch 1: train loss 0.05347144231200218, accuracy 0.3731111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-07 17:23:14,568 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
      "INFO flower 2022-12-07 17:23:14,569 | server.py:144 | FL finished in 20.244424930000605\n",
      "INFO flower 2022-12-07 17:23:14,569 | app.py:192 | app_fit: losses_distributed [(1, 0.06234578847885132), (2, 0.057087348222732544), (3, 0.05480945611000061)]\n",
      "INFO flower 2022-12-07 17:23:14,570 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-07 17:23:14,570 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-07 17:23:14,570 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10156)\u001B[0m [Client 0] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=10155)\u001B[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": "History (loss, distributed):\n\tround 1: 0.06234578847885132\n\tround 2: 0.057087348222732544\n\tround 3: 0.05480945611000061"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=numpyclient_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why Client instead of Nump.Client?\n",
    "The difference comes from the fact that Client expects us to take care of parameter serialization and deserialization.\n",
    "\n",
    "For Flower to be able to send parameters over the network, it eventually needs to turn these parameters into bytes.\n",
    "Turning parameters (e.g., NumPy ndarray’s) into raw bytes is called serialization.\n",
    "Turning raw bytes into something more useful (like NumPy ndarray’s) is called deserialization.\n",
    "Flower needs to do both: it needs to serialize parameters on the server-side and send them to the client,\n",
    "the client needs to deserialize them to use them for local training,\n",
    "and then serialize the updated parameters again to send them back to the server, which (finally!) deserializes them again in order to aggregate them with the updates received from other clients.\n",
    "\n",
    "\n",
    "\n",
    "The only real difference between Client and NumPyClient is that NumPyClient takes care of serialization and deserialization for you.\n",
    "It can do so because it expects you to return parameters as NumPy ndarray’s, and it knows how to handle these. This makes working with machine learning libraries that have good NumPy support (most of them) a breeze.\n",
    "\n",
    "In terms of API, there’s one major difference: all methods in Client take exectly one argument (e.g., FitIns in Client.fit) and return exactly one value (e.g., FitRes in Client.fit).\n",
    "The methods in NumPyClient on the other hand have multiple arguments (e.g., parameters and config in NumPyClient.fit) and multiple return values\n",
    "(e.g., parameters, num_example, and metrics in NumPyClient.fit) if there are multiple things to handle. These *Ins and *Res objects in Client wrap all the individual values you’re used to from NumPyClient."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
